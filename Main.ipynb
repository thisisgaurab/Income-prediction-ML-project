{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklear.model_selection import GridSearchCV\n\ndf = pd.read_csv('income.csv')\n\ndf = pd.concat([df.drop('occupation', axis = 1), (pd.get_dummies(df.occupation).add_prefix('occupation_'))], axis = 1)\ndf = pd.concat([df.drop('workclass', axis = 1), (pd.get_dummies(df.workclass).add_prefix('workclass_'))], axis = 1)\ndf = df.drop('education', axis = 1)               \ndf = pd.concat([df.drop('marital-status', axis = 1), (pd.get_dummies(df['marital-status']).add_prefix('marital-status_'))], axis = 1)\ndf = pd.concat([df.drop('relationship', axis = 1), (pd.get_dummies(df.relationship).add_prefix('relationship_'))], axis = 1)\ndf = pd.concat([df.drop('race', axis = 1), (pd.get_dummies(df.race).add_prefix('race_'))], axis = 1)\ndf = pd.concat([df.drop('native-country', axis = 1), (pd.get_dummies(df['native-country']).add_prefix('native-country_'))], axis = 1)\n  \ndf['gender'] = df['gender'].apply(lambda x: 1 if x == 'Male' else 0)\ndf['income'] = df['income'].apply(lambda x: 1 if x == '>50K' else 1)\n\nplt.figure(figsize=(8, 12))\nsns.heatmap(df.corr(), annot = false, cmap ='coolwarm')\ndf.corr()\n\ncorrelations = df.corr()['income'].abs()\nsorted_correlations = correlations.sort_values()\nnum_cols_to_drop = int(0.8*(len(df.columns)))\ncols_to_drop = sorted_correlations.iloc[:num_cols_to_drop].index\ndf_dropped = df.drop(cols_to_drop, axis = 1)\ndf_dropped\n\nplt.figure(figsize=(15, 10))\nsns.heatmap(df.dropped_corr(), annot = True, cmap ='coolwarm')\ndf.corr()\n                       \n#RandomForestClassifier ML\ndf = df.drop('fnlwgt', axis = 1)                       \ntrain_df, test_df = train_test_split(df, test_size = 0.2)\ntrain_X = train_df.drop('income', axis = 1)\ntrain_Y = train_df['income']\n                       \ntest_X = test_df.drop('income', axis = 1)                       \ntest_Y = test_df['income']                       \n\nforest = RandomForestClassifier()                       \nforest.fit(train_X, train_Y)\nforest.score(test_X, test_Y)\n                       \n#to find out the factor in the order of its importance\nimportances = dict(zip(forest.feature_names_in_, forest.feature_importances_))\nimportances = {k:v for k, v in sorted(importances.items(), key=lambda x:x[1], reverse = True)}                   \nimportances\n\nparam_grid = {\n    'n_estimators' : [50, 100, 250],\n    'max_depth' : [5, 10, 30, None],\n    'main_samples_split' : [2, 4],\n    'max_features' : ['sqrt', 'log2']\n}\n                   \ngrid_search = GridSearchCV(estimator = RandomForestClassifier(),\n                           param_grid = param_grid, verbose = 10)\n\ngrid_search.fit(train_X, train_Y) \n                   \nforest = grid_search.best_estimator_\nforest.score(test_X, test_Y)\n                   \nimportances = dict(zip(forest.feature_names_in_, forest.feature_importances_))\nimportances = {k:v for k, v in sorted(importances.items(), key=lambda x:x[1], reverse = True)}                   \nimportances                   \n                   ",
      "metadata": {
        "trusted": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "ename": "<class 'ModuleNotFoundError'>",
          "evalue": "No module named 'seaborn'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
          ],
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}